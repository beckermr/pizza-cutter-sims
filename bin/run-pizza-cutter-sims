#!/usr/bin/env python
import sys
import copy
import logging
import joblib

import click
import yaml
import numpy as np

import fitsio
from esutil.pbar import PBar

# used to get the DEBUG_PLOT logging level
import pizza_cutter  # noqa

from pizza_cutter_sims.main import run_end2end_pair_with_shear
from pizza_cutter_sims.run_utils import measure_shear_metadetect
from pizza_cutter_sims.run_utils import (
    estimate_m_and_c,
    backend_pool,
    cut_nones,
    get_n_workers,
    timer,
)

ORMASK_CUTS = [True, False]
S2N_CUTS = [7, 8, 9, 10, 15, 20]
MFRAC_CUTS = [0, 1, 2, 5, 8, 10, 20, 50, 80, 100]


def _get_dtype():
    fkeys = ["g1p", "g1m", "g1", "g2p", "g2m", "g2"]
    ikeys = ["s2n_cut", "ormask_cut", "mfrac_cut"]
    dtype = []
    for key in fkeys:
        dtype.append((key, "f8"))
    for key in ikeys:
        dtype += [(key, "i4")]

    dtype += [("weight", "f8")]

    return dtype


def _get_size(n_sims):
    return n_sims * len(S2N_CUTS) * (len(ORMASK_CUTS) + len(MFRAC_CUTS))


def _make_res_arrays(n_sims):
    dt = _get_dtype()
    n = _get_size(n_sims)
    return np.zeros(n, dtype=dt), np.zeros(n, dtype=dt)


def _is_none(res):
    if res is None:
        return True

    if any(res[k] is None for k in res):
        return True

    return False


def _run_pair(args):
    try:
        kwargs, num = args

        pres, mres = run_end2end_pair_with_shear(**kwargs)

        if _is_none(pres) or _is_none(mres):
            return None, None

    except KeyError:
        raise
    except TypeError:
        raise
    except Exception as e:
        import traceback
        print("sim failed: %s\n%s" % (repr(e), traceback.format_exc()), flush=True)
        return None, None

    return pres, mres


def _run_sets_of_pairs(all_args):
    model = all_args[0][0]["cfg"]["metadetect"]["model"]
    if model == "wmom":
        tcut = 1.2
    else:
        tcut = 0.5

    all_res = [_run_pair(arg) for arg in all_args]
    all_res = [r for r in all_res if r[0] is not None and r[1] is not None]
    if len(all_res) > 0:
        wgt = len(all_res)

        pres = {}
        mres = {}
        for key in ["1p", "1m", "2p", "2m", "noshear"]:
            pres[key] = np.hstack([r[0][key] for r in all_res])
            mres[key] = np.hstack([r[1][key] for r in all_res])

        dtype = _get_dtype()
        datap = []
        datam = []
        for ormask_cut in ORMASK_CUTS:
            for s2n_cut in S2N_CUTS:
                pgm = measure_shear_metadetect(
                    pres, s2n_cut=s2n_cut, t_ratio_cut=tcut,
                    ormask_cut=ormask_cut, mfrac_cut=None, model=model,
                )
                mgm = measure_shear_metadetect(
                    mres, s2n_cut=s2n_cut, t_ratio_cut=tcut,
                    ormask_cut=ormask_cut, mfrac_cut=None, model=model,
                )
                if pgm is None or mgm is None:
                    continue

                datap.append(
                    tuple(list(pgm) + [s2n_cut, 0 if ormask_cut else 1, -1, wgt]))
                datam.append(
                    tuple(list(mgm) + [s2n_cut, 0 if ormask_cut else 1, -1, wgt]))

        for mfrac_cut in MFRAC_CUTS:
            for s2n_cut in S2N_CUTS:
                pgm = measure_shear_metadetect(
                    pres, s2n_cut=s2n_cut, t_ratio_cut=tcut,
                    ormask_cut=False, mfrac_cut=mfrac_cut/100, model=model,
                )
                mgm = measure_shear_metadetect(
                    mres, s2n_cut=s2n_cut, t_ratio_cut=tcut,
                    ormask_cut=False, mfrac_cut=mfrac_cut/100, model=model,
                )
                if pgm is None or mgm is None:
                    continue

                datap.append(tuple(list(pgm) + [s2n_cut, -1, mfrac_cut, wgt]))
                datam.append(tuple(list(mgm) + [s2n_cut, -1, mfrac_cut, wgt]))

        return [(np.array(datap, dtype=dtype), np.array(datam, dtype=dtype))]
    else:
        return [(None, None)]


def _measure_m_c(pdata, mdata, n_curr, outputs, cfg):
    with timer("zipping and cutting Nones"):
        if len(outputs) > 0:
            pres, mres = zip(*outputs)
            pres, mres = cut_nones(pres, mres)
        else:
            pres = []
            mres = []

    if len(pres) > 0 and len(mres) > 0:
        with timer("building arrays"):
            for i in range(len(pres)):
                n = pres[i].shape[0]
                pdata[n_curr:n_curr+n] = pres[i]
                mdata[n_curr:n_curr+n] = mres[i]

                for col in ["s2n_cut", "ormask_cut", "mfrac_cut"]:
                    assert np.allclose(
                        pdata[col][n_curr:n_curr+n],
                        mdata[col][n_curr:n_curr+n],
                    )
                n_curr += n

    if n_curr > 0:
        with timer("making cuts"):
            _pdata = pdata[:n_curr]
            _mdata = mdata[:n_curr]
            pmsk = (
                (_pdata["s2n_cut"] == 10)
                & (_pdata["ormask_cut"] == -1)
                & (_pdata["mfrac_cut"] == 10)
            )
            _pdata = _pdata[pmsk]
            _mdata = _mdata[pmsk]

        m, msd, c, csd = estimate_m_and_c(
            _pdata,
            _mdata,
            cfg["shear"]["g"],
            swap12=cfg["shear"]["swap12"],
            jackknife=min(200, len(_pdata)//2) if len(_pdata) >= 200 else None,
            weights=_pdata["weight"],
        )

        msg = """\
# of sims: {n_sims}
noise cancel m   : {m: f} +/- {msd: f} [1e-3, 3-sigma]
noise cancel c   : {c: f} +/- {csd: f} [1e-5, 3-sigma]""".format(
                n_sims=np.sum(_pdata["weight"]),
                m=m/1e-3,
                msd=msd/1e-3 * 3,
                c=c/1e-5,
                csd=csd/1e-5 * 3,
        )
        print(msg, flush=True)

    return pdata, mdata, n_curr


def _gen_args(
    start, end, cfg,
    sim_rng_seeds, gal_rng_seeds, star_rng_seeds, coadd_rng_seeds, mdet_rng_seeds
):

    def _gen():
        for i in range(start, end):
            yield (
                dict(
                    rng_seed=sim_rng_seeds[i],
                    gal_rng_seed=gal_rng_seeds[i],
                    star_rng_seed=star_rng_seeds[i],
                    coadd_rng_seed=coadd_rng_seeds[i],
                    mdet_rng_seed=mdet_rng_seeds[i],
                    cfg=copy.deepcopy(cfg),
                    g1=cfg["shear"]["g"],
                    g2=0,
                    swap12=cfg["shear"]["swap12"],
                ),
                i,
            )

    return _gen


def _gen_chunks(
    n_chunks,
    n_pack,
    n_sims,
    cfg,
    sim_rng_seeds,
    gal_rng_seeds,
    star_rng_seeds,
    coadd_rng_seeds,
    mdet_rng_seeds,
):
    def _gen():
        for chunk in range(n_chunks):
            start = chunk * n_pack
            end = min(start + n_pack, n_sims)
            _agen = _gen_args(
                start,
                end,
                cfg,
                sim_rng_seeds,
                gal_rng_seeds,
                star_rng_seeds,
                coadd_rng_seeds,
                mdet_rng_seeds,
            )
            yield joblib.delayed(_run_sets_of_pairs)([a for a in _agen()])
    return _gen


@click.command()
@click.option('--config', type=str, default="config.yaml", help='config file')
@click.option('--seed', type=int, default=None, help='seed for the RNG', required=True)
@click.option('--output', type=str, default=None, help='output file')
@click.option('--n-sims', type=int, default=1, help='number of sims to run')
@click.option(
    '--log-level', default='warning', type=str,
    help=(
        'python logging level [one of critical error, '
        'warning, info, or debug]')
)
@click.option(
    '--backend', default='local', type=str,
    help=(
        "parallel backend to use (one of 'local', "
        "'loky', 'condor', 'lsf', or 'mpi')"
    )
)
@click.option(
    '--n-workers', default=None, type=int,
    help="number of parallel workers to use",
)
@click.option(
    '--n-report', default=None, type=int,
    help="number of subiterations between which to report results",
)
@click.option(
    '--n-pack', default=1, type=int,
    help="number of sims to pack in a single job",
)
def main(config, seed, output, n_sims, log_level, backend, n_workers, n_report, n_pack):
    """Run simulation(s) and analyze them with pizza cutter coadding and metadetect."""

    if backend == "local":
        logging.basicConfig(stream=sys.stdout)
        for code in ["ngmix", "metadetect", "pizza_cutter", "pizza_cutter_sims"]:
            logging.getLogger(code).setLevel(
                getattr(logging, log_level.upper()))

    if backend == "mpi":
        from mpi4py import MPI
        comm = MPI.COMM_WORLD
        rank = comm.Get_rank()
    else:
        rank = 0

    if rank == 0:
        with open(config, "r") as fp:
            cfg = yaml.safe_load(fp.read())

        rng = np.random.RandomState(seed=seed)
        sim_rng_seeds = rng.randint(low=1, high=2**29, size=n_sims)
        gal_rng_seeds = rng.randint(low=1, high=2**29, size=n_sims)
        coadd_rng_seeds = rng.randint(low=1, high=2**29, size=n_sims)
        mdet_rng_seeds = rng.randint(low=1, high=2**29, size=n_sims)
        star_rng_seeds = rng.randint(low=1, high=2**29, size=n_sims)

    if n_report is None:
        n_report = max(n_sims // 100, 100)

    n_chunks = n_sims // n_pack
    if n_chunks * n_pack < n_sims:
        n_chunks += 1

    n_report_chunks = n_report // n_pack
    if n_report_chunks * n_pack < n_report:
        n_report_chunks += 1
    if n_report_chunks < 1:
        n_report_chunks = 1

    if n_workers is None:
        if backend == "condor":
            n_workers = min(10000, n_chunks)
        elif backend == "lsf":
            n_workers = min(3000, n_chunks)
        else:
            n_workers = min(n_report_chunks, get_n_workers(backend))

    print(
        "running %d sims w/ %d chunks reporting every %d chunks on %d workers" % (
            n_sims,
            n_chunks,
            n_report_chunks,
            n_workers,
        ),
        flush=True,
    )

    pdata, mdata = _make_res_arrays(n_chunks)
    n_curr = 0

    if backend == "local":
        if rank == 0:
            outputs = []
            for chunk in PBar(
                range(n_chunks),
                total=n_chunks, n_bars=79, desc='running jobs'
            ):
                start = chunk * n_pack
                end = min(start + n_pack, n_sims)
                _agen = _gen_args(
                    start,
                    end,
                    cfg,
                    sim_rng_seeds,
                    gal_rng_seeds,
                    star_rng_seeds,
                    coadd_rng_seeds,
                    mdet_rng_seeds,
                )
                outputs += _run_sets_of_pairs([a for a in _agen()])

                n_outputs = len(outputs)
                if (
                    (chunk+1) % n_report_chunks == 0
                    and (n_outputs > 0 or n_curr > 0)
                ):
                    print("\n", end="", flush=True)
                    pdata, mdata, n_curr = _measure_m_c(
                        pdata, mdata, n_curr, outputs, cfg
                    )
                    outputs = []
                    if output is not None and n_curr > 0:
                        with fitsio.FITS(output, 'rw', clobber=True) as fits:
                            fits.write(pdata[:n_curr], extname='plus')
                            fits.write(mdata[:n_curr], extname='minus')
    else:
        if backend == "lsf" and not cfg["metadetect"]["color_dep_psf"]["skip"]:
            pkwargs = {"mem": 6}
        else:
            pkwargs = {}

        with backend_pool(
            backend,
            n_workers=n_workers,
            verbose=100,
            **pkwargs,
        ) as pool:
            if pool is not None and rank == 0:
                _gen = _gen_chunks(
                    n_chunks,
                    n_pack,
                    n_sims,
                    cfg,
                    sim_rng_seeds,
                    gal_rng_seeds,
                    star_rng_seeds,
                    coadd_rng_seeds,
                    mdet_rng_seeds,
                )

                outputs = []
                chunk = 0
                for pr in PBar(
                    pool(_gen()),
                    total=n_chunks,
                    desc="running jobs",
                ):
                    try:
                        res = pr.result()
                    except Exception as e:
                        print(f"failure: {repr(e)}", flush=True)
                    else:
                        outputs += res

                    # report m,c
                    n_outputs = len(outputs)
                    if (
                        (chunk+1) % n_report_chunks == 0
                        and (n_outputs > 0 or n_curr > 0)
                    ):
                        print("\n", end="", flush=True)
                        pdata, mdata, n_curr = _measure_m_c(
                            pdata, mdata, n_curr, outputs, cfg
                        )
                        outputs = []
                        if output is not None and n_curr > 0:
                            with fitsio.FITS(output, 'rw', clobber=True) as fits:
                                fits.write(pdata[:n_curr], extname='plus')
                                fits.write(mdata[:n_curr], extname='minus')

                    chunk += 1

    if rank == 0:
        pdata, mdata, n_curr = _measure_m_c(
            pdata, mdata, n_curr, outputs, cfg
        )
        if output is not None and n_curr > 0:
            with fitsio.FITS(output, 'rw', clobber=True) as fits:
                fits.write(pdata[:n_curr], extname='plus')
                fits.write(mdata[:n_curr], extname='minus')


if __name__ == '__main__':
    main()
